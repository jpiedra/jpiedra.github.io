<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scripting on Jonathan Piedra</title>
    <link>http://jpiedra.github.io/tags/scripting/</link>
    <description>Recent content in Scripting on Jonathan Piedra</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 08 Jul 2018 13:58:48 -0400</lastBuildDate>
    
	<atom:link href="http://jpiedra.github.io/tags/scripting/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Never Update an AWS Security Group Again</title>
      <link>http://jpiedra.github.io/article/never-update-security-group/</link>
      <pubDate>Sun, 08 Jul 2018 13:58:48 -0400</pubDate>
      
      <guid>http://jpiedra.github.io/article/never-update-security-group/</guid>
      <description>&lt;p&gt;Sweat the small stuff! Script that itch you can&amp;rsquo;t scratch&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Scripted S3 Site Deployment with AWS CLI and Powershell, Part 2</title>
      <link>http://jpiedra.github.io/article/s3-site-deploy-2/</link>
      <pubDate>Sun, 11 Feb 2018 13:23:20 -0500</pubDate>
      
      <guid>http://jpiedra.github.io/article/s3-site-deploy-2/</guid>
      <description>&lt;p&gt;In this final post for a two-part series, we&amp;rsquo;ll go over an additional script that can be used to upload all local static site contents to a previously configured Amazon Web Services S3 bucket.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Scripted S3 Site Deployment with AWS CLI and Powershell, Part 1</title>
      <link>http://jpiedra.github.io/article/s3-site-deploy-1/</link>
      <pubDate>Sat, 20 Jan 2018 16:29:20 -0500</pubDate>
      
      <guid>http://jpiedra.github.io/article/s3-site-deploy-1/</guid>
      <description>&lt;p&gt;Amazon Web Services, through their Simple Storage Service (S3), provide an inexpensive and flexible solution for hosting static websites. These would normally be sites that are developed on a local environment (using &lt;a href=&#34;https://gohugo.io/overview/quickstart/&#34;&gt;Hugo&lt;/a&gt; or &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt;), then pushed to either a web server or - in this case - a cloud-based storage platform configured to make the generated pages public. This post discusses a scripted approach to building a bucket you want to use to host an S3 website from scratch.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A simple build script</title>
      <link>http://jpiedra.github.io/article/simple-build-script/</link>
      <pubDate>Wed, 01 Feb 2017 10:51:38 -0500</pubDate>
      
      <guid>http://jpiedra.github.io/article/simple-build-script/</guid>
      <description>&lt;p&gt;Today we go over the process of writing a very simple Bash script. We&amp;rsquo;ll be able to detect whether a build for a &lt;a href=&#34;https://gohugo.io/overview/quickstart/&#34;&gt;Hugo static site&lt;/a&gt; is present, push the files to a Git repository for our website, and automate all the steps involved.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Web API, written using PHP and MySQL - Part 1</title>
      <link>http://jpiedra.github.io/article/php-sql-api-1/</link>
      <pubDate>Sun, 15 Jan 2017 13:20:54 -0500</pubDate>
      
      <guid>http://jpiedra.github.io/article/php-sql-api-1/</guid>
      <description>&lt;p&gt;In this first part of a series on implementing a PHP/MySQL-based API endpoint for our data, we go over some basic principles, as well as stated goals, that will guide the work we&amp;rsquo;ll be undertaking later.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>